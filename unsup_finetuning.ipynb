{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/home/work/CCT/concept_centric_transformers'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting albumentations==1.4.7 (from -r requirements.txt (line 1))\n",
      "  Downloading albumentations-1.4.7-py3-none-any.whl (155 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ipython==8.24.0 (from -r requirements.txt (line 2))\n",
      "  Downloading ipython-8.24.0-py3-none-any.whl (816 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m816.5/816.5 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting lightning-bolts==0.7.0 (from -r requirements.txt (line 3))\n",
      "  Downloading lightning_bolts-0.7.0-py3-none-any.whl (300 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.8/300.8 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting matplotlib==3.8.4 (from -r requirements.txt (line 4))\n",
      "  Downloading matplotlib-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting numpy==1.26.4 (from -r requirements.txt (line 5))\n",
      "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pandas==2.2.2 (from -r requirements.txt (line 6))\n",
      "  Downloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting Pillow==10.3.0 (from -r requirements.txt (line 7))\n",
      "  Downloading pillow-10.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pytorch-lightning==1.9.5 (from -r requirements.txt (line 8))\n",
      "  Downloading pytorch_lightning-1.9.5-py3-none-any.whl (829 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m829.5/829.5 kB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting scikit-learn==1.4.2 (from -r requirements.txt (line 9))\n",
      "  Downloading scikit_learn-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[?25hCollecting scipy==1.13.0 (from -r requirements.txt (line 10))\n",
      "  Downloading scipy-1.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting scikit-image==0.23.2 (from -r requirements.txt (line 11))\n",
      "  Downloading scikit_image-0.23.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.7/14.7 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting timm==0.9.12 (from -r requirements.txt (line 12))\n",
      "  Downloading timm-0.9.12-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torch==2.3.0 (from -r requirements.txt (line 13))\n",
      "  Downloading torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m123.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0mm^C\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:albumentations.check_version:A new version of Albumentations is available: 2.0.8 (you have 1.4.7). Upgrade using: pip install --upgrade albumentations\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/work/.local/lib/python3.10/site-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(numpy, tp_name):\n",
      "/home/work/.local/lib/python3.10/site-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(numpy, tp_name):\n",
      "/home/work/.local/lib/python3.10/site-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:34: UnderReviewWarning: The feature generate_power_seq is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  \"lr_options\": generate_power_seq(LEARNING_RATE_CIFAR, 11),\n",
      "/home/work/.local/lib/python3.10/site-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:92: UnderReviewWarning: The feature FeatureMapContrastiveTask is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  contrastive_task: Union[FeatureMapContrastiveTask] = FeatureMapContrastiveTask(\"01, 02, 11\"),\n",
      "/home/work/.local/lib/python3.10/site-packages/pl_bolts/losses/self_supervised_learning.py:228: UnderReviewWarning: The feature AmdimNCELoss is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  self.nce_loss = AmdimNCELoss(tclip)\n",
      "INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/vit_tiny_patch16_224.augreg_in21k_ft_in1k)\n",
      "model.safetensors: 100% 22.9M/22.9M [00:00<00:00, 73.2MB/s]\n",
      "INFO:timm.models._hub:[timm/vit_tiny_patch16_224.augreg_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "INFO:pytorch_lightning.utilities.rank_zero:Using 16bit None Automatic Mixed Precision (AMP)\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.utilities.rank_zero:You are using a CUDA device ('CUDA GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "WARNING:pytorch_lightning.loggers.tensorboard:Missing logger folder: checkpoints/lightning_logs\n",
      "/home/work/.local/lib/python3.10/site-packages/albumentations/core/validation.py:38: DeprecationWarning: ShiftScaleRotate is deprecated. Please use Affine transform instead .\n",
      "  original_init(self, **validated_kwargs)\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | model     | SlotCVITQSA        | 6.0 M \n",
      "1 | criterion | CrossEntropyLoss   | 0     \n",
      "2 | train_acc | MulticlassAccuracy | 0     \n",
      "3 | val_acc   | MulticlassAccuracy | 0     \n",
      "-------------------------------------------------\n",
      "6.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.0 M     Total params\n",
      "11.940    Total estimated model params size (MB)\n",
      "2025-07-30 12:42:27.901688: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-07-30 12:42:27.901768: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-07-30 12:42:27.903512: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-07-30 12:42:28.993574: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Sanity Checking: 0it [00:00, ?it/s]Traceback (most recent call last):\n",
      "  File \"/home/work/CCT/concept_centric_transformers/embryo_unsup.py\", line 218, in <module>\n",
      "    main()\n",
      "  File \"/home/work/CCT/concept_centric_transformers/embryo_unsup.py\", line 213, in main\n",
      "    trainer.fit(model, datamodule=dm)\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 608, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py\", line 38, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 650, in _fit_impl\n",
      "    self._run(model, ckpt_path=self.ckpt_path)\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1112, in _run\n",
      "    results = self._run_stage()\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1191, in _run_stage\n",
      "    self._run_train()\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1204, in _run_train\n",
      "    self._run_sanity_check()\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1276, in _run_sanity_check\n",
      "    val_loop.run()\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py\", line 199, in run\n",
      "    self.advance(*args, **kwargs)\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\", line 152, in advance\n",
      "    dl_outputs = self.epoch_loop.run(self._data_fetcher, dl_max_batches, kwargs)\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py\", line 199, in run\n",
      "    self.advance(*args, **kwargs)\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\", line 121, in advance\n",
      "    batch = next(data_fetcher)\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/pytorch_lightning/utilities/fetching.py\", line 184, in __next__\n",
      "    return self.fetching_function()\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/pytorch_lightning/utilities/fetching.py\", line 265, in fetching_function\n",
      "    self._fetch_next_batch(self.dataloader_iter)\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/pytorch_lightning/utilities/fetching.py\", line 280, in _fetch_next_batch\n",
      "    batch = next(iterator)\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 631, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1346, in _next_data\n",
      "    return self._process_data(data)\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1372, in _process_data\n",
      "    data.reraise()\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/torch/_utils.py\", line 705, in reraise\n",
      "    raise exception\n",
      "ValueError: Caught ValueError in DataLoader worker process 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n",
      "    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/home/work/CCT/concept_centric_transformers/embryo_unsup.py\", line 47, in __getitem__\n",
      "    image = self.transform(image=image)[\"image\"]\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/albumentations/core/composition.py\", line 256, in __call__\n",
      "    data = t(**data)\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/albumentations/core/transforms_interface.py\", line 97, in __call__\n",
      "    return self.apply_with_params(params, **kwargs)\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/albumentations/core/transforms_interface.py\", line 108, in apply_with_params\n",
      "    res[key] = target_function(arg, **params)\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/albumentations/augmentations/crops/transforms.py\", line 127, in apply\n",
      "    return F.center_crop(img, self.height, self.width)\n",
      "  File \"/home/work/.local/lib/python3.10/site-packages/albumentations/augmentations/crops/functional.py\", line 164, in center_crop\n",
      "    raise ValueError(\n",
      "ValueError: Requested crop size (224, 224) is larger than the image size (192, 256)\n",
      "\n",
      "                                   \r"
     ]
    }
   ],
   "source": [
    "!python embryo_unsup.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
